{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "Given a sequence of characters, can we **predict the next possible character?** For example given a character sequence comprising of 10 characters: `How are yo`, the model is expected to predict the next possible character, such as `u`, completing the sequence as `How are you`. The same process can be repeated with latest characters, such as last 10, to generate further characters. That is, in the next step, the first 10 characters to input will be (i.e., excluding the very first `H` and including the last generated `u`) : `ow are you`. Taking this new sequence as input, the model is expected to predict next character such as `?`, making the overall result as `How are you?` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 0 Load Dataset\n",
    "We first load the dataset to train our generative model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = load_doc('dataset/ed_sheraan.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The club isn't the best place to find a lover\n",
      "So the bar is where I go (mmmm)\n",
      "Me and my friends at the table doing shots\n",
      "Drinking fast and then we talk slow (mmmm)\n",
      "And you come over and start up a conversation with just me\n",
      "And trust me I'll give it a chance now (mmmm)\n",
      "Take my hand, stop, put Van The Man on the jukebox\n",
      "And then we start to dance\n",
      "And now I'm singing like\n",
      "Girl, you know I want your love\n",
      "Your love was handmade for somebody like me\n",
      "Come on now, follow my lead\n",
      "I may be crazy, don't mind me\n",
      "Say, boy, let's not talk too much\n",
      "Grab on my waist and put that body on me\n",
      "Come on now, follow my lead\n",
      "Come, come on now, follow my lead (mmmm)\n"
     ]
    }
   ],
   "source": [
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Line Breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = raw_text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lowercase Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lowercased = [aToken.lower() for aToken in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = ' '.join(tokens_lowercased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the club isn't the best place to find a lover so the bar is where i go (mmmm) me and my friends at the table doing shots drinking fast and then we talk slow (mmmm) and you come over and start up a conversation with just me and trust me i'll give it a chance now (mmmm) take my hand, stop, put van the man on the jukebox and then we start to dance and now i'm singing like girl, you know i want your love your love was handmade for somebody like me come on now, follow my lead i may be crazy, don't mind me say, boy, let's not talk too much grab on my waist and put that body on me come on now, follow my lead come, come on now, follow my lead (mmmm)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sequence format\n",
    "\n",
    "Every sequences in the list for training contains __(sequence_length+1)__ characters, where the first\n",
    "__sequence_length__ characters are input character sequence and the __(sequence_length+1)__ th character is\n",
    "the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for i in range(sequence_length, len(preprocessed_dataset)):\n",
    "    seq = preprocessed_dataset[i-sequence_length: i+1]\n",
    "    #print(seq)\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the club is',\n",
       " 'he club isn',\n",
       " \"e club isn'\",\n",
       " \" club isn't\",\n",
       " \"club isn't \",\n",
       " \"lub isn't t\",\n",
       " \"ub isn't th\",\n",
       " \"b isn't the\",\n",
       " \" isn't the \",\n",
       " \"isn't the b\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences :  639\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Sequences : \", len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Save the Sequenced Dataset to File\n",
    "The saved processed dataset can be used later as starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '\\n'.join(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filePath = 'dataset/char_sequences.txt'\n",
    "with open(out_filePath, 'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_sequences.txt  ed_sheraan.txt  rhyme.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Encode Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 The Set of Characters in our sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_set = sorted(list(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Integer Mapping\n",
    "We represent each of the character in the sequences by a corresponding integer for fedding into\n",
    "our ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict((c, i) for i, c in enumerate(character_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " \"'\": 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " 'a': 6,\n",
       " 'b': 7,\n",
       " 'c': 8,\n",
       " 'd': 9,\n",
       " 'e': 10,\n",
       " 'f': 11,\n",
       " 'g': 12,\n",
       " 'h': 13,\n",
       " 'i': 14,\n",
       " 'j': 15,\n",
       " 'k': 16,\n",
       " 'l': 17,\n",
       " 'm': 18,\n",
       " 'n': 19,\n",
       " 'o': 20,\n",
       " 'p': 21,\n",
       " 'r': 22,\n",
       " 's': 23,\n",
       " 't': 24,\n",
       " 'u': 25,\n",
       " 'v': 26,\n",
       " 'w': 27,\n",
       " 'x': 28,\n",
       " 'y': 29,\n",
       " 'z': 30}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:: 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size:: {}\".format(len(mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Save the Mapping for Later Use (Character Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(mapping, open('others/mapping.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Sequence Encoding\n",
    "We replace each of the character in sequences with their corresponding mapping, as obtained\n",
    "above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int_encoded_sequences = list()\n",
    "\n",
    "for line in lines:\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    int_encoded_sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24, 13, 10, 1, 8, 17, 25, 7, 1, 14, 23],\n",
       " [13, 10, 1, 8, 17, 25, 7, 1, 14, 23, 19],\n",
       " [10, 1, 8, 17, 25, 7, 1, 14, 23, 19, 2],\n",
       " [1, 8, 17, 25, 7, 1, 14, 23, 19, 2, 24],\n",
       " [8, 17, 25, 7, 1, 14, 23, 19, 2, 24, 1],\n",
       " [17, 25, 7, 1, 14, 23, 19, 2, 24, 1, 24],\n",
       " [25, 7, 1, 14, 23, 19, 2, 24, 1, 24, 13],\n",
       " [7, 1, 14, 23, 19, 2, 24, 1, 24, 13, 10],\n",
       " [1, 14, 23, 19, 2, 24, 1, 24, 13, 10, 1],\n",
       " [14, 23, 19, 2, 24, 1, 24, 13, 10, 1, 7]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_encoded_sequences[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Split Sequences for Input and Output\n",
    "For any given sequence, the first (such as, 10) characters are treated are input feature **X** and the last character is treated as the ouput i.e., __y__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "sequences = array(int_encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 13, 10, ...,  1, 14, 23],\n",
       "       [13, 10,  1, ..., 14, 23, 19],\n",
       "       [10,  1,  8, ..., 23, 19,  2],\n",
       "       ...,\n",
       "       [29,  1, 17, ..., 18, 18, 18],\n",
       "       [ 1, 17, 10, ..., 18, 18, 18],\n",
       "       [17, 10,  6, ..., 18, 18,  4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 13, 10, ...,  7,  1, 14],\n",
       "       [13, 10,  1, ...,  1, 14, 23],\n",
       "       [10,  1,  8, ..., 14, 23, 19],\n",
       "       ...,\n",
       "       [29,  1, 17, ...,  3, 18, 18],\n",
       "       [ 1, 17, 10, ..., 18, 18, 18],\n",
       "       [17, 10,  6, ..., 18, 18, 18]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 19,  2, 24,  1, 24, 13, 10,  1,  7, 10, 23, 24,  1, 21, 17,  6,\n",
       "        8, 10,  1, 24, 20,  1, 11, 14, 19,  9,  1,  6,  1, 17, 20, 26, 10,\n",
       "       22,  1, 23, 20,  1, 24, 13, 10,  1,  7,  6, 22,  1, 14, 23,  1, 27,\n",
       "       13, 10, 22, 10,  1, 14,  1, 12, 20,  1,  3, 18, 18, 18, 18,  4,  1,\n",
       "       18, 10,  1,  6, 19,  9,  1, 18, 29,  1, 11, 22, 14, 10, 19,  9, 23,\n",
       "        1,  6, 24,  1, 24, 13, 10,  1, 24,  6,  7, 17, 10,  1,  9, 20, 14,\n",
       "       19, 12,  1, 23, 13, 20, 24, 23,  1,  9, 22, 14, 19, 16, 14, 19, 12,\n",
       "        1, 11,  6, 23, 24,  1,  6, 19,  9,  1, 24, 13, 10, 19,  1, 27, 10,\n",
       "        1, 24,  6, 17, 16,  1, 23, 17, 20, 27,  1,  3, 18, 18, 18, 18,  4,\n",
       "        1,  6, 19,  9,  1, 29, 20, 25,  1,  8, 20, 18, 10,  1, 20, 26, 10,\n",
       "       22,  1,  6, 19,  9,  1, 23, 24,  6, 22, 24,  1, 25, 21,  1,  6,  1,\n",
       "        8, 20, 19, 26, 10, 22, 23,  6, 24, 14, 20, 19,  1, 27, 14, 24, 13,\n",
       "        1, 15, 25, 23, 24,  1, 18, 10,  1,  6, 19,  9,  1, 24, 22, 25, 23,\n",
       "       24,  1, 18, 10,  1, 14,  2, 17, 17,  1, 12, 14, 26, 10,  1, 14, 24,\n",
       "        1,  6,  1,  8, 13,  6, 19,  8, 10,  1, 19, 20, 27,  1,  3, 18, 18,\n",
       "       18, 18,  4,  1, 24,  6, 16, 10,  1, 18, 29,  1, 13,  6, 19,  9,  5,\n",
       "        1, 23, 24, 20, 21,  5,  1, 21, 25, 24,  1, 26,  6, 19,  1, 24, 13,\n",
       "       10,  1, 18,  6, 19,  1, 20, 19,  1, 24, 13, 10,  1, 15, 25, 16, 10,\n",
       "        7, 20, 28,  1,  6, 19,  9,  1, 24, 13, 10, 19,  1, 27, 10,  1, 23,\n",
       "       24,  6, 22, 24,  1, 24, 20,  1,  9,  6, 19,  8, 10,  1,  6, 19,  9,\n",
       "        1, 19, 20, 27,  1, 14,  2, 18,  1, 23, 14, 19, 12, 14, 19, 12,  1,\n",
       "       17, 14, 16, 10,  1, 12, 14, 22, 17,  5,  1, 29, 20, 25,  1, 16, 19,\n",
       "       20, 27,  1, 14,  1, 27,  6, 19, 24,  1, 29, 20, 25, 22,  1, 17, 20,\n",
       "       26, 10,  1, 29, 20, 25, 22,  1, 17, 20, 26, 10,  1, 27,  6, 23,  1,\n",
       "       13,  6, 19,  9, 18,  6,  9, 10,  1, 11, 20, 22,  1, 23, 20, 18, 10,\n",
       "        7, 20,  9, 29,  1, 17, 14, 16, 10,  1, 18, 10,  1,  8, 20, 18, 10,\n",
       "        1, 20, 19,  1, 19, 20, 27,  5,  1, 11, 20, 17, 17, 20, 27,  1, 18,\n",
       "       29,  1, 17, 10,  6,  9,  1, 14,  1, 18,  6, 29,  1,  7, 10,  1,  8,\n",
       "       22,  6, 30, 29,  5,  1,  9, 20, 19,  2, 24,  1, 18, 14, 19,  9,  1,\n",
       "       18, 10,  1, 23,  6, 29,  5,  1,  7, 20, 29,  5,  1, 17, 10, 24,  2,\n",
       "       23,  1, 19, 20, 24,  1, 24,  6, 17, 16,  1, 24, 20, 20,  1, 18, 25,\n",
       "        8, 13,  1, 12, 22,  6,  7,  1, 20, 19,  1, 18, 29,  1, 27,  6, 14,\n",
       "       23, 24,  1,  6, 19,  9,  1, 21, 25, 24,  1, 24, 13,  6, 24,  1,  7,\n",
       "       20,  9, 29,  1, 20, 19,  1, 18, 10,  1,  8, 20, 18, 10,  1, 20, 19,\n",
       "        1, 19, 20, 27,  5,  1, 11, 20, 17, 17, 20, 27,  1, 18, 29,  1, 17,\n",
       "       10,  6,  9,  1,  8, 20, 18, 10,  5,  1,  8, 20, 18, 10,  1, 20, 19,\n",
       "        1, 19, 20, 27,  5,  1, 11, 20, 17, 17, 20, 27,  1, 18, 29,  1, 17,\n",
       "       10,  6,  9,  1,  3, 18, 18, 18, 18,  4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 One-hot Encode\n",
    "We one-hot encode each of the character in **X** and **y**. We use **to_categorical()** method of keras for the purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "vocab_size = len(mapping)\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 10, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Define the Model\n",
    "As input the model takes **sequence_length** of time steps each containing **vocab_size** of one hot encoded features. Then use single LSTM layer with 75 memory units (i.e., can be changed with trail and error). Finally, the output layer is one vector with size of **vocab_size**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                32100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31)                2356      \n",
      "=================================================================\n",
      "Total params: 34,456\n",
      "Trainable params: 34,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Fit model\n",
    "The model is trained 100 training epochs (i.e., can be changed with trail and error). The model uses **categorical_crossentropy** as loss function for its a multi-class classification problem. Using efficient **adam** for gradient descent. The model reports **accuracy** metric at the end of training of each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 2s - loss: 3.3685 - acc: 0.1565\n",
      "Epoch 2/100\n",
      " - 0s - loss: 3.1170 - acc: 0.2113\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.9500 - acc: 0.2113\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.9047 - acc: 0.2113\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.8702 - acc: 0.2113\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.8488 - acc: 0.2113\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.8217 - acc: 0.2113\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.7900 - acc: 0.2113\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.7484 - acc: 0.2113\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.6953 - acc: 0.2175\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.6640 - acc: 0.2457\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.6059 - acc: 0.2660\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.5431 - acc: 0.2895\n",
      "Epoch 14/100\n",
      " - 0s - loss: 2.5096 - acc: 0.2848\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2.4485 - acc: 0.3271\n",
      "Epoch 16/100\n",
      " - 0s - loss: 2.4135 - acc: 0.3255\n",
      "Epoch 17/100\n",
      " - 0s - loss: 2.3478 - acc: 0.3412\n",
      "Epoch 18/100\n",
      " - 0s - loss: 2.3068 - acc: 0.3505\n",
      "Epoch 19/100\n",
      " - 0s - loss: 2.2544 - acc: 0.3865\n",
      "Epoch 20/100\n",
      " - 0s - loss: 2.1991 - acc: 0.3756\n",
      "Epoch 21/100\n",
      " - 0s - loss: 2.1851 - acc: 0.4053\n",
      "Epoch 22/100\n",
      " - 0s - loss: 2.1234 - acc: 0.4257\n",
      "Epoch 23/100\n",
      " - 0s - loss: 2.0880 - acc: 0.4272\n",
      "Epoch 24/100\n",
      " - 0s - loss: 2.0416 - acc: 0.4507\n",
      "Epoch 25/100\n",
      " - 0s - loss: 2.0006 - acc: 0.4789\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.9583 - acc: 0.4992\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.9327 - acc: 0.5102\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.8860 - acc: 0.5039\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.8393 - acc: 0.5305\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.7900 - acc: 0.5321\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.7449 - acc: 0.5415\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.7120 - acc: 0.5477\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.6858 - acc: 0.5462\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.6542 - acc: 0.5540\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.6150 - acc: 0.5665\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.5557 - acc: 0.5900\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.5211 - acc: 0.5900\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.4846 - acc: 0.6009\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.4398 - acc: 0.6009\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.4164 - acc: 0.6103\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.3957 - acc: 0.6182\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.3369 - acc: 0.6275\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.2905 - acc: 0.6557\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.2541 - acc: 0.6620\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.2206 - acc: 0.6620\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.1770 - acc: 0.6948\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.1330 - acc: 0.6964\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.1063 - acc: 0.7042\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.0935 - acc: 0.7121\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.0433 - acc: 0.7355\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.0067 - acc: 0.7480\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.9746 - acc: 0.7418\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9403 - acc: 0.7653\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.9248 - acc: 0.7480\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.8898 - acc: 0.7887\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.8526 - acc: 0.7887\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.8138 - acc: 0.8122\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.7836 - acc: 0.8200\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.7648 - acc: 0.8263\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.7199 - acc: 0.8529\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6837 - acc: 0.8638\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.6579 - acc: 0.8748\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6310 - acc: 0.8811\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.6030 - acc: 0.8983\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.5888 - acc: 0.9030\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.5556 - acc: 0.9139\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.5335 - acc: 0.9186\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.5046 - acc: 0.9311\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4845 - acc: 0.9358\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4614 - acc: 0.9421\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4432 - acc: 0.9515\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4182 - acc: 0.9546\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3981 - acc: 0.9593\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3808 - acc: 0.9640\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3566 - acc: 0.9734\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3455 - acc: 0.9734\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3327 - acc: 0.9750\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3070 - acc: 0.9765\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3061 - acc: 0.9765\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.2893 - acc: 0.9765\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.2732 - acc: 0.9812\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.2598 - acc: 0.9765\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.2526 - acc: 0.9844\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.2403 - acc: 0.9797\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.2214 - acc: 0.9844\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.2113 - acc: 0.9859\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.2030 - acc: 0.9828\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1942 - acc: 0.9828\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1870 - acc: 0.9859\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1805 - acc: 0.9875\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1732 - acc: 0.9890\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.1669 - acc: 0.9890\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1557 - acc: 0.9890\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1504 - acc: 0.9875\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1456 - acc: 0.9922\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1388 - acc: 0.9906\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1335 - acc: 0.9890\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1258 - acc: 0.9890\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1221 - acc: 0.9875\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1197 - acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffaec1c82e8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Generate Text \n",
    "We now use the trained model to generate character sequences.\n",
    "\n",
    "As input the model takes **sequence_length** number of characters and generate or predict the next character that is likely to appear next. We then use the newly generated character in the sequence as the last character, while removing/truncating the very first character to generate another new character. The process is continued for the total number of characters expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        #encoded = encoded.reshape(1, encoded.shape[0], encoded.shape[1])\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text\n",
    "\n",
    "# load the model\n",
    "model = load_model('models/model.h5')\n",
    "# load the mapping\n",
    "mapping = load(open('others/mapping.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Test some cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Sequence:** so the bar is where i go (mmmm) me and my friends at the table doing shots drinking fast and then we talk slow (mmmm) and you come over and start up a conversation with just me and trust me i'll give it a chance now (mmmm) take my hand,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so the bar is where i go (mmmm) me and my friends at the table doing shots drinking fast and then we start to dance and now i'm singing like girl, you know i want your love was handmade for somebody like me come on now, fol\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 10, 'so the bar', 213))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Sequence:** take my hand, stop, put van the man on the jukebox and then we start to dance and now i'm singing like girl, you know i want your love your love was handmade for somebody lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take my hand, stop, put van the man on the jukebox and then we start to dance and now i'm singing like girl, you know i want your love was handmade for somebody like me come on now, follow my lead come, come on\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 10, 'take my ha', 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Sequence:** start to dance and now i'm singing like girl, you know i want your love your love was handmade for somebody like me come on now, follow my lead i may be crazy, don't mind me say, boy, let's not talk too much grab on my waist and put that body on me come on now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to dance and now i'm singing like girl, you know i want your love was handmade for somebody like me come on now, follow my lead come, come on now, follow my lead come, come on now, follow my lead come, co\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 10, 'start to d', 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0 Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
